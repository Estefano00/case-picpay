{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe LeitorCSV\n",
    "\n",
    "* __init__ – cria SparkSession local.\n",
    "* ler(caminho) – lê o CSV original de voos com inferSchema=True, devolvendo um DataFrame.\n",
    "\n",
    "## Classe EnriquecedorVentos\n",
    "\n",
    "A classe automatiza o enriquecimento da base de voos com fuso (GMT) e velocidade do vento, gerando as colunas:\n",
    "\n",
    "gmt_origin, gmt_dest\n",
    "\n",
    "dep_real, arr_real, arr_real_arred\n",
    "\n",
    "wind_origin, wind_dest\n",
    "\n",
    "O processo consulta duas APIs públicas a AirportDB e Open‑Meteo (a API Weatherbit API se mostrou muito limitada na quantidade de requisições), e calcula horários de partidas e chegadas reais, arredonda para “blocos” de 1 hora (passo de 30 min) e grava o resultado num CSV.\n",
    " Nenhuma linha é descartada; quando não há dado disponível o campo fica None.\n",
    "\n",
    "---\n",
    "\n",
    "### Construtor  __init__(df_voos, spark)\n",
    "\n",
    "* guarda o DataFrame Spark original e a SparkSession\n",
    "* cria self.aero_infos, dicionário onde serão armazenados dados de cada aeroporto.\n",
    "\n",
    "---\n",
    "\n",
    "### coletar_aeroportos()\n",
    "\n",
    "* varre colunas origin e dest; gera o conjunto de IATA únicos.\n",
    "* inicializa self.aero_infos com chaves vazias ({IATA:{}}) para cada código.\n",
    "\n",
    "---\n",
    "\n",
    "### buscar_coordenadas()\n",
    "\n",
    "* para cada código em self.aero_infos faz GET na AirportDB;\n",
    "* salva lat/lon; se a consulta falhar apenas emite um aviso e continua.\n",
    "\n",
    "---\n",
    "\n",
    "### baixar_vento()\n",
    "\n",
    "* descobre primeiro/último dia presente em time_hour; adiciona +1 dia.\n",
    "* para cada aeroporto com coordenada válida faz chamada à Open‑Meteo (endpoint archive).\n",
    "* grava em self.aero_infos[cod]:\n",
    "\n",
    "  * GMT (deslocamento em horas, usando utc_offset_seconds)\n",
    "  * vento → dicionário { \"YYYY‑MM‑DD HH:MM:SS\": velocidade }.\n",
    "\n",
    "---\n",
    "\n",
    "### adicionar_gmt()\n",
    "\n",
    "* cria um broadcast só com aeroportos que têm GMT;\n",
    "* UDF preenche colunas gmt_origin e gmt_dest (inteiro, ex. ‑3).\n",
    "\n",
    "---\n",
    "\n",
    "### calcular_partida_chegada()\n",
    "\n",
    "* dep_real = to_timestamp(time_hour) + (dep_delay minutos) – se faltam dados, vira null.\n",
    "* UDF chegada converte dep_real + air_time + GMTs em string local de chegada (arr_real).\n",
    "\n",
    "  * falhas (GMT ausente, problema no parse etc.) devolvem None em vez de lançar exceção.\n",
    "\n",
    "---\n",
    "\n",
    "### arredonda_meia_hora(dt_str)\n",
    "\n",
    "* função estática que arredonda um timestamp string para o início da hora ou hora seguinte, de acordo com os minutos (00‑29 → HH:00; 30‑59 → HH+1:00).\n",
    "* retorna None se a entrada também for nula ou inválida.\n",
    "\n",
    "---\n",
    "\n",
    "### criar_arr_redondo()\n",
    "\n",
    "* aplica a UDF arredonda_meia_hora sobre arr_real\n",
    "* cria a coluna arr_real_arred (usada para casar com vento de destino).\n",
    "\n",
    "---\n",
    "\n",
    "### adicionar_velocidade_vento()\n",
    "\n",
    "* faz broadcast do mapa {IATA: dicionário de vento}.\n",
    "* UDF vento_origem procura velocidade pela chave “YYYY‑MM‑DD HH:MM:SS” derivada de time_hour\n",
    "* UDF vento_destino faz o mesmo usando arr_real_arred.\n",
    "* campos permanecem None se chave ou aeroporto não estiverem no mapa.\n",
    "\n",
    "---\n",
    "\n",
    "### garantir_integridade()\n",
    "\n",
    "* adiciona colunas faltantes cheias de None; garante que cada linha possua todas as sete colunas novas, evitando perda de registros ao gravar CSV.\n",
    "\n",
    "---\n",
    "\n",
    "### salvar_csv(saida=\"base_enriquecida.csv\")\n",
    "\n",
    "* grava o DataFrame final em modo overwrite com cabeçalho, na pasta indicada.\n",
    "* útil para inspeção posterior ou ingestão num data lake.\n",
    "\n",
    "---\n",
    "\n",
    "### executar(saida=\"base_enriquecida.csv\")\n",
    "\n",
    "Pipeline orquestrador; chama, em ordem:\n",
    "\n",
    "1. coletar_aeroportos\n",
    "2. buscar_coordenadas\n",
    "3. baixar_vento\n",
    "4. adicionar_gmt\n",
    "5. calcular_partida_chegada\n",
    "6. criar_arr_redondo\n",
    "7. adicionar_velocidade_vento\n",
    "8. salvar_csv\n",
    "\n",
    "Retorna o DataFrame enriquecido; imprime mensagens em cada etapa para facilitar depuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133684,
     "status": "ok",
     "timestamp": 1745000668959,
     "user": {
      "displayName": "Estefano Nascimento",
      "userId": "00926361525390533690"
     },
     "user_tz": 180
    },
    "id": "R2O-5_TLgB25",
    "outputId": "e12d3a29-d465-406f-c2d2-5a28e7288f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Lendo CSV …\n",
      "🔹 Coletando aeroportos …\n",
      "  ✅ 107 aeroportos detectados\n",
      "🔹 Buscando coordenadas …\n",
      "  ⚠️  BQN: coordenadas não encontradas\n",
      "  ⚠️  PSE: coordenadas não encontradas\n",
      "  ⚠️  SJU: coordenadas não encontradas\n",
      "  ⚠️  HNL: coordenadas não encontradas\n",
      "  ⚠️  STT: coordenadas não encontradas\n",
      "  ⚠️  ANC: coordenadas não encontradas\n",
      "🔹 Baixando vento horário (Open‑Meteo) …\n",
      "  ✅ JFK: 8784 horas de vento\n",
      "  ✅ LGA: 8784 horas de vento\n",
      "  ✅ EWR: 8784 horas de vento\n",
      "  ✅ IAH: 8784 horas de vento\n",
      "  ✅ PBI: 8784 horas de vento\n",
      "  ✅ BOS: 8784 horas de vento\n",
      "  ✅ CLT: 8784 horas de vento\n",
      "  ✅ SNA: 8784 horas de vento\n",
      "  ✅ XNA: 8784 horas de vento\n",
      "  ✅ SYR: 8784 horas de vento\n",
      "  ✅ JAX: 8784 horas de vento\n",
      "  ✅ CHS: 8784 horas de vento\n",
      "  ✅ MEM: 8784 horas de vento\n",
      "  ✅ SAN: 8784 horas de vento\n",
      "  ✅ DCA: 8784 horas de vento\n",
      "  ✅ MYR: 8784 horas de vento\n",
      "  ✅ MDW: 8784 horas de vento\n",
      "  ✅ BNA: 8784 horas de vento\n",
      "  ✅ BTV: 8784 horas de vento\n",
      "  ✅ EGE: 8784 horas de vento\n",
      "  ✅ AVL: 8784 horas de vento\n",
      "  ✅ IND: 8784 horas de vento\n",
      "  ✅ LGB: 8784 horas de vento\n",
      "  ✅ BDL: 8784 horas de vento\n",
      "  ✅ GSO: 8784 horas de vento\n",
      "  ✅ CVG: 8784 horas de vento\n",
      "  ✅ BUR: 8784 horas de vento\n",
      "  ✅ GSP: 8784 horas de vento\n",
      "  ✅ GRR: 8784 horas de vento\n",
      "  ✅ PDX: 8784 horas de vento\n",
      "  ✅ SJC: 8784 horas de vento\n",
      "  ✅ OMA: 8784 horas de vento\n",
      "  ✅ OKC: 8784 horas de vento\n",
      "  ✅ PVD: 8784 horas de vento\n",
      "  ✅ DSM: 8784 horas de vento\n",
      "  ✅ CAE: 8784 horas de vento\n",
      "  ✅ EYW: 8784 horas de vento\n",
      "  ✅ ACK: 8784 horas de vento\n",
      "  ✅ ABQ: 8784 horas de vento\n",
      "  ✅ SBN: 8784 horas de vento\n",
      "  ✅ MIA: 8784 horas de vento\n",
      "  ✅ IAD: 8784 horas de vento\n",
      "  ✅ LAX: 8784 horas de vento\n",
      "  ✅ LAS: 8784 horas de vento\n",
      "  ✅ MSP: 8784 horas de vento\n",
      "  ✅ DTW: 8784 horas de vento\n",
      "  ✅ RSW: 8784 horas de vento\n",
      "  ✅ PHX: 8784 horas de vento\n",
      "  ✅ BUF: 8784 horas de vento\n",
      "  ✅ DEN: 8784 horas de vento\n",
      "  ✅ SLC: 8784 horas de vento\n",
      "  ✅ SEA: 8784 horas de vento\n",
      "  ✅ RDU: 8784 horas de vento\n",
      "  ✅ AUS: 8784 horas de vento\n",
      "  ✅ HOU: 8784 horas de vento\n",
      "  ✅ RIC: 8784 horas de vento\n",
      "  ✅ MCI: 8784 horas de vento\n",
      "  ✅ SAT: 8784 horas de vento\n",
      "  ✅ SDF: 8784 horas de vento\n",
      "  ✅ CRW: 8784 horas de vento\n",
      "  ✅ OAK: 8784 horas de vento\n",
      "  ✅ SMF: 8784 horas de vento\n",
      "  ✅ TUL: 8784 horas de vento\n",
      "  ✅ TYS: 8784 horas de vento\n",
      "  ✅ BHM: 8784 horas de vento\n",
      "  ✅ BZN: 8784 horas de vento\n",
      "  ✅ PSP: 8784 horas de vento\n",
      "  ✅ LEX: 8784 horas de vento\n",
      "  ✅ ATL: 8784 horas de vento\n",
      "  ✅ ORD: 8784 horas de vento\n",
      "  ✅ FLL: 8784 horas de vento\n",
      "  ✅ TPA: 8784 horas de vento\n",
      "  ✅ BWI: 8784 horas de vento\n",
      "  ✅ MSY: 8784 horas de vento\n",
      "  ✅ CMH: 8784 horas de vento\n",
      "  ✅ STL: 8784 horas de vento\n",
      "  ✅ PHL: 8784 horas de vento\n",
      "  ✅ PWM: 8784 horas de vento\n",
      "  ✅ CAK: 8784 horas de vento\n",
      "  ✅ HDN: 8784 horas de vento\n",
      "  ✅ BGR: 8784 horas de vento\n",
      "  ✅ ILM: 8784 horas de vento\n",
      "  ✅ MVY: 8784 horas de vento\n",
      "  ✅ MCO: 8784 horas de vento\n",
      "  ✅ SFO: 8784 horas de vento\n",
      "  ✅ DFW: 8784 horas de vento\n",
      "  ✅ MKE: 8784 horas de vento\n",
      "  ✅ ROC: 8784 horas de vento\n",
      "  ✅ SRQ: 8784 horas de vento\n",
      "  ✅ PIT: 8784 horas de vento\n",
      "  ✅ CLE: 8784 horas de vento\n",
      "  ✅ JAC: 8784 horas de vento\n",
      "  ✅ SAV: 8784 horas de vento\n",
      "  ✅ DAY: 8784 horas de vento\n",
      "  ✅ ALB: 8784 horas de vento\n",
      "  ✅ MHT: 8784 horas de vento\n",
      "  ✅ MSN: 8784 horas de vento\n",
      "  ✅ ORF: 8784 horas de vento\n",
      "  ✅ MTJ: 8784 horas de vento\n",
      "  ✅ CHO: 8784 horas de vento\n",
      "  ✅ TVC: 8784 horas de vento\n",
      "🔹 Inserindo GMT …\n",
      "🔹 Calculando dep_real e arr_real …\n",
      "🔹 Criando arr_real_arred (chegada arredondada) …\n",
      "🔹 Inserindo velocidade do vento …\n",
      "🔹 Salvando CSV …\n",
      "✅ Arquivos gravados em /content/base_enriquecida.csv\n",
      "🔸 Linhas finais: 336776\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────── IMPORTS\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Classe de suporte: Carregar DataFrame\n",
    "# ---------------------------------------------------------------------------\n",
    "class LeitorCSV:\n",
    "    \"\"\"Abre o Spark localmente e lê o CSV de voos.\"\"\"\n",
    "\n",
    "    def __init__(self, nome_app=\"voos‑spark\"):\n",
    "        self.spark = (\n",
    "            SparkSession.builder.appName(nome_app)\n",
    "            .master(\"local[*]\")\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "            .getOrCreate()\n",
    "        )\n",
    "\n",
    "    def ler(self, caminho):\n",
    "        print(\"🔹 Lendo CSV …\")\n",
    "        return (\n",
    "            self.spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(caminho)\n",
    "        )\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Classe principal: Enriquecimento\n",
    "# ---------------------------------------------------------------------------\n",
    "class EnriquecedorVentos:\n",
    "    \"\"\"Executa todo o fluxo de enriquecimento.\"\"\"\n",
    "\n",
    "    URL_AIRPORT = \"https://airportdb.io/api/v1/airport/K{code}?apiToken={key}\"\n",
    "    URL_METEO = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    API_AIRPORT_KEY = '8618d96aca630e2b49d157fe2fa9a49aebeb24dd8eea5ad4832145ebf6b215e65a2d508691ff175571fc6d896443484d'\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2.0 – Construtor\n",
    "    # ---------------------------------------------------------------------\n",
    "    def __init__(self, df_voos, spark):\n",
    "        self.df = df_voos\n",
    "        self.spark = spark\n",
    "        self.aero_infos = {}  # {IATA: {lat, lon, GMT, vento}}\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2.1 – Coleta todos os aeroportos que aparecem na base\n",
    "    # ---------------------------------------------------------------------\n",
    "    def coletar_aeroportos(self):\n",
    "        print(\"🔹 Coletando aeroportos …\")\n",
    "        codigos = (\n",
    "            self.df.select(\"origin\").union(self.df.select(\"dest\"))\n",
    "            .distinct().rdd.flatMap(lambda r: r).collect()\n",
    "        )\n",
    "        self.aero_infos = {c: {} for c in codigos}\n",
    "        print(f\"  ✅ {len(codigos)} aeroportos detectados\")\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2.2 – Buscar latitude/longitude de cada aeroporto via API\n",
    "    # ---------------------------------------------------------------------\n",
    "    def buscar_coordenadas(self):\n",
    "        print(\"🔹 Buscando coordenadas …\")\n",
    "        for cod in self.aero_infos:\n",
    "            url = self.URL_AIRPORT.format(code=cod, key=self.API_AIRPORT_KEY)\n",
    "            r = requests.get(url, timeout=10)\n",
    "            if r.ok:\n",
    "                js = r.json()\n",
    "                self.aero_infos[cod][\"lat\"] = float(js[\"latitude_deg\"])\n",
    "                self.aero_infos[cod][\"lon\"] = float(js[\"longitude_deg\"])\n",
    "            else:\n",
    "                print(f\"  ⚠️  {cod}: coordenadas não encontradas\")\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2.3 – Baixar série histórica de vento e GMT de cada aeroporto\n",
    "    # ---------------------------------------------------------------------\n",
    "    def baixar_vento(self):\n",
    "        print(\"🔹 Baixando vento horário (Open‑Meteo) …\")\n",
    "        dmin, dmax = (\n",
    "            self.df.select(F.to_date(\"time_hour\").alias(\"d\")).agg(F.min(\"d\"), F.max(\"d\")).first()\n",
    "        )\n",
    "        dmax += timedelta(days=1)\n",
    "\n",
    "        sess = requests.Session()\n",
    "        sess.mount(\"https://\", HTTPAdapter(max_retries=Retry(total=5, backoff_factor=1.5)))\n",
    "\n",
    "        for cod, info in self.aero_infos.items():\n",
    "            if \"lat\" not in info:\n",
    "                continue\n",
    "            params = dict(\n",
    "                latitude=info[\"lat\"], longitude=info[\"lon\"],\n",
    "                start_date=dmin.strftime(\"%Y-%m-%d\"), end_date=dmax.strftime(\"%Y-%m-%d\"),\n",
    "                hourly=\"windspeed_10m\", timezone=\"auto\"\n",
    "            )\n",
    "            try:\n",
    "                js = sess.get(self.URL_METEO, params=params, timeout=20).json()\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️  {cod}: falha Open‑Meteo ({e})\")\n",
    "                continue\n",
    "            info[\"GMT\"] = int(js[\"utc_offset_seconds\"] / 3600)\n",
    "            info[\"vento\"] = {\n",
    "                t.replace(\"T\", \" \") + \":00\": v\n",
    "                for t, v in zip(js[\"hourly\"][\"time\"], js[\"hourly\"][\"windspeed_10m\"])\n",
    "            }\n",
    "            print(f\"  ✅ {cod}: {len(info['vento'])} horas de vento\")\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2.4 – Adicionar colunas GMT\n",
    "    # --------------------------------------------------------------------\n",
    "    def adicionar_gmt(self):\n",
    "        print(\"🔹 Inserindo GMT …\")\n",
    "        gmap = {c: v[\"GMT\"] for c, v in self.aero_infos.items() if \"GMT\" in v}\n",
    "        bc = self.spark.sparkContext.broadcast(gmap)\n",
    "\n",
    "        udf_gmt = F.udf(lambda c: bc.value.get(c), T.IntegerType())\n",
    "        self.df = (\n",
    "            self.df.withColumn(\"gmt_origin\", udf_gmt(\"origin\"))\n",
    "                   .withColumn(\"gmt_dest\", udf_gmt(\"dest\"))\n",
    "        )\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2.5  Horários real de partida e chegada\n",
    "    # -----------------------------------------------------------------\n",
    "    def calcular_partida_chegada(self):\n",
    "        print(\"🔹 Calculando dep_real e arr_real …\")\n",
    "\n",
    "        # Coluna de partida real (dep_real) – se 'base' for null, devolve null\n",
    "        self.df = (\n",
    "            self.df\n",
    "            .withColumn(\"base\", F.to_timestamp(\"time_hour\"))          # pode virar null\n",
    "            .withColumn(\n",
    "                \"dep_real\",\n",
    "                F.when(\n",
    "                    F.col(\"base\").isNull() | F.col(\"dep_delay\").isNull(),\n",
    "                    F.lit(None).cast(\"timestamp\")\n",
    "                ).otherwise(\n",
    "                    F.expr(\"base + INTERVAL 1 MINUTE * dep_delay\")\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Broadcast de GMTs disponíveis\n",
    "        gmt_map = {c: v[\"GMT\"] for c, v in self.aero_infos.items() if \"GMT\" in v}\n",
    "        bc = self.spark.sparkContext.broadcast(gmt_map)\n",
    "\n",
    "        def chegada(dep_real, orig, dest, dur):\n",
    "            \"\"\"Retorna string chegada ou None; nunca lança exceção.\"\"\"\n",
    "            if None in (dep_real, dur):                             # dados faltantes\n",
    "                return None\n",
    "            go, gd = bc.value.get(orig), bc.value.get(dest)\n",
    "            if None in (go, gd):                                    # GMT faltante\n",
    "                return None\n",
    "            try:\n",
    "                dep_real = dep_real.replace(tzinfo=timezone(timedelta(hours=go)))\n",
    "                arr_utc = dep_real.astimezone(timezone.utc) + timedelta(minutes=dur)\n",
    "                arr_dest = arr_utc.astimezone(timezone(timedelta(hours=gd)))\n",
    "                return arr_dest.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            except Exception:\n",
    "                return None                                         # falha → nulo\n",
    "\n",
    "        udf_chegada = F.udf(chegada, T.StringType())\n",
    "        self.df = self.df.withColumn(\n",
    "            \"arr_real\",\n",
    "            udf_chegada(\"dep_real\", \"origin\", \"dest\", \"air_time\"),\n",
    "        )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2.6  Arredondar em 30 min (usa arr_real, mas devolve None se arr_real nulo)\n",
    "    # -----------------------------------------------------------------\n",
    "    @staticmethod\n",
    "    def arredonda_meia_hora(dt_str):\n",
    "        if dt_str is None:\n",
    "            return None\n",
    "        try:\n",
    "            dt = datetime.strptime(dt_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            return None\n",
    "        meia_hora = dt.replace(minute=0, second=0)\n",
    "        if dt.minute >= 30:\n",
    "            meia_hora += timedelta(hours=1)\n",
    "        return meia_hora.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2.7 – Criar coluna de chegada arredondada\n",
    "    # -----------------------------------------------------------------\n",
    "    def criar_arr_redondo(self):\n",
    "        \"\"\"\n",
    "        Gera a coluna arr_real_arred (hora de chegada arredondada ao bloco de 30 min).\n",
    "\n",
    "        • Se arr_real for nulo ou tiver formato inválido → devolve None\n",
    "        • Mantém TODAS as linhas do DataFrame\n",
    "        \"\"\"\n",
    "        print(\"🔹 Criando arr_real_arred (chegada arredondada) …\")\n",
    "\n",
    "        # UDF que aplica a função arredonda_meia_hora segura para nulos\n",
    "        udf_round = F.udf(self.arredonda_meia_hora, T.StringType())\n",
    "\n",
    "        self.df = self.df.withColumn(\"arr_real_arred\", udf_round(\"arr_real\"))\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2.8  Velocidade do vento (deixa resultado nulo se chave não existir)\n",
    "    # -----------------------------------------------------------------\n",
    "    def adicionar_velocidade_vento(self):\n",
    "        print(\"🔹 Inserindo velocidade do vento …\")\n",
    "\n",
    "        vmap = {c: v[\"vento\"] for c, v in self.aero_infos.items() if \"vento\" in v}\n",
    "        bc = self.spark.sparkContext.broadcast(vmap)\n",
    "\n",
    "        def vento_origem(cod, ts):\n",
    "            if ts is None: return None\n",
    "            chave = ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            return bc.value.get(cod, {}).get(chave)\n",
    "\n",
    "        def vento_destino(cod, ts_str):\n",
    "            if not ts_str: return None\n",
    "            return bc.value.get(cod, {}).get(ts_str)\n",
    "\n",
    "        self.df = (\n",
    "            self.df\n",
    "            .withColumn(\"wind_origin\",\n",
    "                        F.udf(vento_origem, T.DoubleType())(\"origin\", F.to_timestamp(\"time_hour\")))\n",
    "            .withColumn(\"wind_dest\",\n",
    "                        F.udf(vento_destino, T.DoubleType())(\"dest\", \"arr_real_arred\"))\n",
    "        )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2.9  Garante que todas as linhas continuem existindo\n",
    "    # -----------------------------------------------------------------\n",
    "    def garantir_integridade(self):\n",
    "        \"\"\"Adiciona colunas vazias (cheias de None) que porventura não existam.\"\"\"\n",
    "        colunas_esperadas = [\n",
    "            \"gmt_origin\", \"gmt_dest\",\n",
    "            \"dep_real\", \"arr_real\", \"arr_real_arred\",\n",
    "            \"wind_origin\", \"wind_dest\",\n",
    "        ]\n",
    "        for col in colunas_esperadas:\n",
    "            if col not in self.df.columns:\n",
    "                self.df = self.df.withColumn(col, F.lit(None))\n",
    "   # ---------------------------------------------------------------------\n",
    "    # 2.10 – Salvar CSV\n",
    "    # ---------------------------------------------------------------------\n",
    "    def salvar_csv(self, saida=\"base_enriquecida.csv\"):\n",
    "        print(\"🔹 Salvando CSV …\")\n",
    "        self.df.write.mode(\"overwrite\").option(\"header\", True).csv(saida)\n",
    "        print(f\"✅ Arquivos gravados em {Path(saida).resolve()}\")\n",
    "    # ---------------------------------------------------------------------\n",
    "    # 2.11 – Executando o pipeline\n",
    "    # ---------------------------------------------------------------------\n",
    "    def executar(self, saida=\"base_enriquecida.csv\"):\n",
    "        self.coletar_aeroportos()\n",
    "        self.buscar_coordenadas()\n",
    "        self.baixar_vento()\n",
    "        self.adicionar_gmt()\n",
    "        self.calcular_partida_chegada()\n",
    "        self.criar_arr_redondo()\n",
    "        self.adicionar_velocidade_vento()\n",
    "        self.salvar_csv(saida)\n",
    "        return self.df\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Enriquecendo\n",
    "# ---------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    leitor = LeitorCSV()\n",
    "    voos = leitor.ler(\"airports-database.csv\")\n",
    "    voos.count()\n",
    "    pipe = EnriquecedorVentos(voos, leitor.spark)\n",
    "    df_final = pipe.executar(\"base_enriquecida.csv\")\n",
    "    print(\"🔸 Linhas finais:\", df_final.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe Perguntas\n",
    "\n",
    "A classe encapsula todas as queries de análise pedidas no case. Ela recebe um único DataFrame Spark no construtor, e cada método responde exatamente a uma das 17 perguntas, imprimindo no console o resultado. Todos os métodos utilizam apenas APIs padrão do PySpark (groupBy, agg, filter, orderBy, janelas) – simples de ler, manter e sem dependências externas.\n",
    "\n",
    "---\n",
    "\n",
    "### __Construtor init__(df)\n",
    "\n",
    "* Construtor: guarda o DataFrame passado em self.df, que será reutilizado por todos os métodos – evita leituras repetidas de disco.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_1\n",
    "\n",
    "* Usa count() para obter o número total de registros na tabela de voos.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_2\n",
    "\n",
    "* Aplica filter() com condição dep_time IS NULL AND arr_time IS NULL;\n",
    "  conta as linhas resultantes → total de voos cancelados.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_3\n",
    "\n",
    "* Remove cancelados (ambos horários nulos) e calcula avg(dep_delay) via agg().\n",
    "  Retorna atraso médio na decolagem.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_4\n",
    "\n",
    "* Agrupa por dest, conta linhas, ordena por count decrescente e faz limit(5) → 5 aeroportos com mais pousos.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_5\n",
    "\n",
    "* Agrupa por par (origin, dest), conta e ordena decrescente;\n",
    "  first() devolve rota mais frequente.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_6\n",
    "\n",
    "* Agrupa por carrier, calcula média de arr_delay, ordena e pega os 5 maiores.\n",
    "  Retorna as 5 companhias com maior atraso médio na chegada.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_7\n",
    "\n",
    "* Cria coluna dow (day‑of‑week) a partir de time_hour,\n",
    "  agrupa, conta e pega o maior → dia da semana com mais voos\n",
    "  (Spark: 1 = Domingo, 7 = Sábado).\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_8\n",
    "\n",
    "* Marca atrasado = dep_delay > 30, agrupa por month,\n",
    "  calcula (sum(atrasado) / total) * 100.\n",
    "  Resultado: percentual mensal de voos com decolagem atrasada > 30 min.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_9\n",
    "\n",
    "* Filtra somente voos com dest == 'SEA', agrupa por origin, conta e ordena.\n",
    "  Retorna origem mais comum para Seattle (SEA).\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_10\n",
    "\n",
    "* Repete lógica de dow, mas agora faz avg(dep_delay) por dia.\n",
    "  Mostra atraso médio de partida por dia da semana.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_11\n",
    "\n",
    "* Agrupa (origin, dest), média de air_time;\n",
    "  maior valor = rota com maior tempo médio de voo.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_12\n",
    "\n",
    "* Usa janela Window.partitionBy(\"origin\").orderBy(desc(\"count\"))\n",
    "  para ranquear destinos dentro de cada origem; mantém rank = 1.\n",
    "  Resultado: destino mais frequente por aeroporto de origem.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_13\n",
    "\n",
    "* Agrupa rotas e calcula stddev_pop(air_time); ordena e pega 3 maiores.\n",
    "  Dá as três rotas com maior variação do tempo de voo.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_14\n",
    "\n",
    "* Filtra linhas onde dep_delay > 60, tira avg(arr_delay).\n",
    "  Mostra média de atraso na chegada quando a partida atrasou > 1 h.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_15\n",
    "\n",
    "* Conta voos por (month, day), depois média de count dentro de cada mês.\n",
    "  Retorna média de voos diários por mês.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_16\n",
    "\n",
    "* Filtra arr_delay > 30, agrupa rotas e pega top‑3 em contagem.\n",
    "  Entrega as três rotas mais comuns com chegada atrasada > 30 min.\n",
    "\n",
    "---\n",
    "\n",
    "### pergunta_17\n",
    "\n",
    "* Requisito repete a lógica da 12 → método simplesmente chama pergunta_12().\n",
    "\n",
    "---\n",
    "\n",
    "### executar_todas\n",
    "\n",
    "* Itera de 1 a 17, faz getattr(self, f\"pergunta_{i}\") e executa.\n",
    "  Facilita rodar todo o questionário em um único comando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30254,
     "status": "ok",
     "timestamp": 1744992587449,
     "user": {
      "displayName": "Estefano Nascimento",
      "userId": "00926361525390533690"
     },
     "user_tz": 180
    },
    "id": "1s49yF3DgPJI",
    "outputId": "17bf2e36-8512-4d66-cf5f-e25af3eaa53c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta 1, resposta: 336776\n",
      "Pergunta 2, resposta: 8255\n",
      "Pergunta 3, resposta: 12.58 minutos\n",
      "Pergunta 4, resposta (dest, pousos): [('ORD', 17283), ('ATL', 17215), ('LAX', 16174), ('BOS', 15508), ('MCO', 14082)]\n",
      "Pergunta 5, resposta: JFK → LAX (11262 voos)\n",
      "Pergunta 6, resposta (carrier, atraso médio): [('F9', 21.92), ('FL', 20.12), ('EV', 15.8), ('YV', 15.56), ('OO', 11.93)]\n",
      "Pergunta 7, resposta: Dia‑da‑semana 2 (50690 voos)\n",
      "Pergunta 8, resposta (mês, % atrasado): [(1, 12.41), (2, 12.75), (3, 14.94), (4, 15.99), (5, 15.34), (6, 20.24), (7, 20.98), (8, 14.45), (9, 8.77), (10, 9.34), (11, 8.76), (12, 17.31)]\n",
      "Pergunta 9, resposta: JFK (2092 voos)\n",
      "Pergunta 10, resposta (dow, atraso médio): [(1, 11.59), (2, 14.78), (3, 10.63), (4, 11.8), (5, 16.15), (6, 14.7), (7, 7.65)]\n",
      "Pergunta 11, resposta: JFK → HNL (média 623.09 min)\n",
      "Pergunta 12, resposta (origem → destino): [('EWR', 'ORD'), ('JFK', 'LAX'), ('LGA', 'ATL')]\n",
      "Pergunta 13, resposta (rota, desvio): [('EWR→HNL', 21.24), ('LGA→MYR', 20.68), ('JFK→HNL', 20.66)]\n",
      "Pergunta 14, resposta: 119.05 minutos\n",
      "Pergunta 15, resposta (mês, média diária): [(1, 871.1), (2, 891.1), (3, 930.1), (4, 944.3), (5, 928.9), (6, 941.4), (7, 949.2), (8, 946.0), (9, 919.1), (10, 931.9), (11, 908.9), (12, 907.6)]\n",
      "Pergunta 16, resposta (rota, qtd): [('LGA→ATL', 1563), ('JFK→LAX', 1286), ('LGA→ORD', 1188)]\n",
      "Pergunta 12, resposta (origem → destino): [('EWR', 'ORD'), ('JFK', 'LAX'), ('LGA', 'ATL')]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf‑8 -*-\n",
    "\"\"\"\n",
    "Classe Perguntas\n",
    "────────────────\n",
    "Resolve, com PySpark, as 17 perguntas pedidas sobre o DataFrame de voos.\n",
    "Cada método usa **operações básicas** (groupBy, agg, orderBy, filter, etc.)\n",
    "e imprime a resposta no formato:\n",
    "\n",
    "    Pergunta X, resposta: <resultado>\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "\n",
    "class Perguntas:\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Recebe o DataFrame de voos já carregado em self.df\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "\n",
    "    # ───────────────────────── 1\n",
    "    def pergunta_1(self):\n",
    "        \"\"\"Número total de voos.\"\"\"\n",
    "        total = self.df.count()\n",
    "        print(f\"Pergunta 1, resposta: {total}\")\n",
    "\n",
    "    # ───────────────────────── 2\n",
    "    def pergunta_2(self):\n",
    "        \"\"\"Voos cancelados = dep_time e arr_time são nulos.\"\"\"\n",
    "        cancelados = (\n",
    "            self.df.filter(F.col(\"dep_time\").isNull() & F.col(\"arr_time\").isNull())\n",
    "            .count()\n",
    "        )\n",
    "        print(f\"Pergunta 2, resposta: {cancelados}\")\n",
    "\n",
    "    def pergunta_3(self):\n",
    "        \"\"\"Atraso médio na partida (dep_delay), excluindo voos cancelados.\"\"\"\n",
    "        # Filtra voos que NÃO são cancelados (dep_time e arr_time não nulos)\n",
    "        df_validos = self.df.filter(\n",
    "            (F.col(\"dep_time\").isNotNull()) &\n",
    "            (F.col(\"arr_time\").isNotNull())\n",
    "        )\n",
    "        # Calcula a média de dep_delay sobre esse subconjunto\n",
    "        media = df_validos.agg(F.avg(\"dep_delay\")).first()[0]\n",
    "        print(f\"Pergunta 3, resposta: {media:.2f} minutos\")\n",
    "\n",
    "    # ───────────────────────── 4\n",
    "    def pergunta_4(self):\n",
    "        \"\"\"Top‑5 aeroportos de destino (mais pousos).\"\"\"\n",
    "        top5 = (\n",
    "            self.df.groupBy(\"dest\").count().orderBy(F.desc(\"count\")).limit(5).collect()\n",
    "        )\n",
    "        print(\"Pergunta 4, resposta (dest, pousos):\", [(r[\"dest\"], r[\"count\"]) for r in top5])\n",
    "\n",
    "    # ───────────────────────── 5\n",
    "    def pergunta_5(self):\n",
    "        \"\"\"Rota (origin‑dest) mais frequente.\"\"\"\n",
    "        rota = (\n",
    "            self.df.groupBy(\"origin\", \"dest\")\n",
    "            .count()\n",
    "            .orderBy(F.desc(\"count\"))\n",
    "            .first()\n",
    "        )\n",
    "        print(f\"Pergunta 5, resposta: {rota['origin']} → {rota['dest']} ({rota['count']} voos)\")\n",
    "\n",
    "    # ───────────────────────── 6\n",
    "    def pergunta_6(self):\n",
    "        \"\"\"Top‑5 cias com maior atraso médio na chegada.\"\"\"\n",
    "        top5 = (\n",
    "            self.df.groupBy(\"carrier\")\n",
    "            .agg(F.avg(\"arr_delay\").alias(\"media_atraso\"))\n",
    "            .orderBy(F.desc(\"media_atraso\"))\n",
    "            .limit(5)\n",
    "            .collect()\n",
    "        )\n",
    "        print(\n",
    "            \"Pergunta 6, resposta (carrier, atraso médio):\",\n",
    "            [(r[\"carrier\"], round(r[\"media_atraso\"], 2)) for r in top5],\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 7\n",
    "    def pergunta_7(self):\n",
    "        \"\"\"Dia da semana com mais voos (1=Dom, 7=Sáb no Spark).\"\"\"\n",
    "        dias = (\n",
    "            self.df.withColumn(\"dow\", F.dayofweek(\"time_hour\"))\n",
    "            .groupBy(\"dow\")\n",
    "            .count()\n",
    "            .orderBy(F.desc(\"count\"))\n",
    "            .first()\n",
    "        )\n",
    "        print(f\"Pergunta 7, resposta: Dia‑da‑semana {dias['dow']} ({dias['count']} voos)\")\n",
    "\n",
    "    # ───────────────────────── 8\n",
    "    def pergunta_8(self):\n",
    "        \"\"\"Percentual mensal de voos c/ atraso de partida >30 min.\"\"\"\n",
    "        atrasos = (\n",
    "            self.df.withColumn(\"atrasado\", F.col(\"dep_delay\") > 30)\n",
    "            .groupBy(\"month\")\n",
    "            .agg(\n",
    "                (F.sum(F.col(\"atrasado\").cast(\"int\")) / F.count(\"*\") * 100).alias(\n",
    "                    \"perc_atraso\"\n",
    "                )\n",
    "            )\n",
    "            .orderBy(\"month\")\n",
    "            .collect()\n",
    "        )\n",
    "        print(\n",
    "            \"Pergunta 8, resposta (mês, % atrasado):\",\n",
    "            [(r[\"month\"], round(r[\"perc_atraso\"], 2)) for r in atrasos],\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 9\n",
    "    def pergunta_9(self):\n",
    "        \"\"\"Origem mais comum para voos que pousaram em SEA.\"\"\"\n",
    "        origem = (\n",
    "            self.df.filter(F.col(\"dest\") == \"SEA\")\n",
    "            .groupBy(\"origin\")\n",
    "            .count()\n",
    "            .orderBy(F.desc(\"count\"))\n",
    "            .first()\n",
    "        )\n",
    "        print(f\"Pergunta 9, resposta: {origem['origin']} ({origem['count']} voos)\")\n",
    "\n",
    "    # ───────────────────────── 10\n",
    "    def pergunta_10(self):\n",
    "        \"\"\"Média de dep_delay por dia da semana.\"\"\"\n",
    "        medias = (\n",
    "            self.df.withColumn(\"dow\", F.dayofweek(\"time_hour\"))\n",
    "            .groupBy(\"dow\")\n",
    "            .agg(F.avg(\"dep_delay\").alias(\"media\"))\n",
    "            .orderBy(\"dow\")\n",
    "            .collect()\n",
    "        )\n",
    "        print(\n",
    "            \"Pergunta 10, resposta (dow, atraso médio):\",\n",
    "            [(r[\"dow\"], round(r[\"media\"], 2)) for r in medias],\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 11\n",
    "    def pergunta_11(self):\n",
    "        \"\"\"Rota com maior tempo médio de voo (air_time).\"\"\"\n",
    "        rota = (\n",
    "            self.df.groupBy(\"origin\", \"dest\")\n",
    "            .agg(F.avg(\"air_time\").alias(\"media\"))\n",
    "            .orderBy(F.desc(\"media\"))\n",
    "            .first()\n",
    "        )\n",
    "        print(\n",
    "            f\"Pergunta 11, resposta: {rota['origin']} → {rota['dest']} \"\n",
    "            f\"(média {round(rota['media'],2)} min)\"\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 12\n",
    "    def pergunta_12(self):\n",
    "        \"\"\"Destino mais comum para cada origem.\"\"\"\n",
    "        janela = Window.partitionBy(\"origin\").orderBy(F.desc(\"count\"))\n",
    "        destino_frequente = (\n",
    "            self.df.groupBy(\"origin\", \"dest\")\n",
    "            .count()\n",
    "            .withColumn(\"rank\", F.row_number().over(janela))\n",
    "            .filter(\"rank = 1\")\n",
    "            .select(\"origin\", \"dest\")\n",
    "            .collect()\n",
    "        )\n",
    "        print(\n",
    "            \"Pergunta 12, resposta (origem → destino):\",\n",
    "            [(r[\"origin\"], r[\"dest\"]) for r in destino_frequente],\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 13\n",
    "    def pergunta_13(self):\n",
    "        \"\"\"3 rotas com maior desvio‑padrão (variação) do air_time.\"\"\"\n",
    "        rotas = (\n",
    "            self.df.groupBy(\"origin\", \"dest\")\n",
    "            .agg(F.stddev_pop(\"air_time\").alias(\"std\"))\n",
    "            .orderBy(F.desc(\"std\"))\n",
    "            .limit(3)\n",
    "            .collect()\n",
    "        )\n",
    "        print(\n",
    "            \"Pergunta 13, resposta (rota, desvio):\",\n",
    "            [\n",
    "                (f\"{r['origin']}→{r['dest']}\", round(r[\"std\"], 2))\n",
    "                for r in rotas\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 14\n",
    "    def pergunta_14(self):\n",
    "        \"\"\"Média de arr_delay quando dep_delay > 60 min.\"\"\"\n",
    "        media = (\n",
    "            self.df.filter(F.col(\"dep_delay\") > 60)\n",
    "            .agg(F.avg(\"arr_delay\"))\n",
    "            .first()[0]\n",
    "        )\n",
    "        print(f\"Pergunta 14, resposta: {round(media,2)} minutos\")\n",
    "\n",
    "    # ───────────────────────── 15\n",
    "    def pergunta_15(self):\n",
    "        \"\"\"Média de voos diários para cada mês.\"\"\"\n",
    "        diarios = (\n",
    "            self.df.groupBy(\"month\", \"day\")\n",
    "            .count()\n",
    "            .groupBy(\"month\")\n",
    "            .agg(F.avg(\"count\").alias(\"media_dia\"))\n",
    "            .orderBy(\"month\")\n",
    "            .collect()\n",
    "        )\n",
    "        print(\n",
    "            \"Pergunta 15, resposta (mês, média diária):\",\n",
    "            [(r[\"month\"], round(r[\"media_dia\"], 1)) for r in diarios],\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 16\n",
    "    def pergunta_16(self):\n",
    "        \"\"\"3 rotas mais comuns com arr_delay > 30 min.\"\"\"\n",
    "        rotas = (\n",
    "            self.df.filter(F.col(\"arr_delay\") > 30)\n",
    "            .groupBy(\"origin\", \"dest\")\n",
    "            .count()\n",
    "            .orderBy(F.desc(\"count\"))\n",
    "            .limit(3)\n",
    "            .collect()\n",
    "        )\n",
    "        print(\n",
    "            \"Pergunta 16, resposta (rota, qtd):\",\n",
    "            [(f\"{r['origin']}→{r['dest']}\", r[\"count\"]) for r in rotas],\n",
    "        )\n",
    "\n",
    "    # ───────────────────────── 17\n",
    "    def pergunta_17(self):\n",
    "        \"\"\"Principal destino para cada origem (mesmo que 12, mas exigido).\"\"\"\n",
    "        self.pergunta_12()  # já resolve; reutilizamos\n",
    "\n",
    "    # ───────────────────────── EXECUTA TODAS\n",
    "    def executar_todas(self):\n",
    "        \"\"\"Chama uma a uma, na ordem.\"\"\"\n",
    "        for i in range(1, 18):\n",
    "            metodo = getattr(self, f\"pergunta_{i}\")\n",
    "            metodo()\n",
    "\n",
    "\n",
    "perguntas = Perguntas(df_final)\n",
    "perguntas.executar_todas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perguntas\n",
    "\n",
    "### Pergunta 1\n",
    "\n",
    "**Qual é o número total de voos no conjunto de dados?**\n",
    "\n",
    "Resposta: 336776\n",
    "\n",
    "### Pergunta 2\n",
    "\n",
    "**Quantos voos foram cancelados? (Considerando que voos cancelados têm dep_time e arr_time nulos)**\n",
    "\n",
    "Resposta: 8255\n",
    "\n",
    "### Pergunta 3\n",
    "\n",
    "**Qual é o atraso médio na partida dos voos (dep_delay)?**\n",
    "\n",
    "Resposta: 12.58 minutos\n",
    "\n",
    "### Pergunta 4\n",
    "\n",
    "**Quais são os 5 aeroportos com maior número de pousos?**\n",
    "\n",
    "Resposta:\n",
    "\n",
    "| dest | n Pousos |\n",
    "| ---- | -------- |\n",
    "| ORD  | 17.283   |\n",
    "| ATL  | 17.215   |\n",
    "| LAX  | 16.174   |\n",
    "| BOS  | 15.508   |\n",
    "| MCO  | 14.082   |\n",
    "\n",
    "### Pergunta 5\n",
    "\n",
    "**Qual é a rota mais frequente (par origin-dest)?**\n",
    "\n",
    "Resposta: JFK → LAX (11262 voos)\n",
    "\n",
    "### Pergunta 6\n",
    "\n",
    "**Quais são as 5 companhias aéreas com maior tempo médio de atraso na chegada? (Exiba também o tempo)**\n",
    "\n",
    "Resposta:\n",
    "\n",
    "[('F9', 21.92), ('FL', 20.12), ('EV', 15.8), ('YV', 15.56), ('OO', 11.93)]\n",
    "\n",
    "| Companhia | Atraso |\n",
    "| --------- | ------ |\n",
    "| F9        | 21.92  |\n",
    "| FL        | 20.12  |\n",
    "| EV        | 15.8   |\n",
    "| YV        | 15.56  |\n",
    "| OO        | 11.93  |\n",
    "\n",
    "### Pergunta 7\n",
    "\n",
    "**Qual é o dia da semana com maior número de voos?**\n",
    "\n",
    "Resposta: Segunda Feira 50690 voos\n",
    "\n",
    "### Pergunta 8\n",
    "\n",
    "**Qual o percentual mensal dos voos tiveram atraso na partida superior a 30 minutos?**\n",
    "\n",
    "Resposta:\n",
    "\n",
    "| Mês | Percentual |\n",
    "| ---- | ---------- |\n",
    "| 1    | 12.41      |\n",
    "| 2    | 12.75      |\n",
    "| 3    | 14.94      |\n",
    "| 4    | 15.99      |\n",
    "| 5    | 15.34      |\n",
    "| 6    | 20.24      |\n",
    "| 7    | 20.98      |\n",
    "| 8    | 14.45      |\n",
    "| 9    | 8.77       |\n",
    "| 10   | 9.34       |\n",
    "| 11   | 8.76       |\n",
    "| 12   | 17.31      |\n",
    "\n",
    "### Pergunta 9\n",
    "\n",
    "**Qual a origem mais comum para voos que pousaram em Seattle (SEA)?**\n",
    "\n",
    "Resposta: JFK (2092 voos)\n",
    "\n",
    "### Pergunta 10\n",
    "\n",
    "**Qual é a média de atraso na partida dos voos (dep_delay) para cada dia da semana?**\n",
    "\n",
    "Resposta:\n",
    "\n",
    "| Dia da semana | Percentual |\n",
    "| ------------- | ---------- |\n",
    "| Domingo       | 11.59      |\n",
    "| Segunda feira | 14.78      |\n",
    "| Terça feira   | 10.63      |\n",
    "| Quarta feira  | 11.8       |\n",
    "| Quinta feira  | 16.15      |\n",
    "| Sexta feira   | 14.7       |\n",
    "| Sábado        | 7.65)      |\n",
    "\n",
    "### Pergunta 11\n",
    "\n",
    "**Qual é a rota que teve o maior tempo de voo médio (air_time)?**\n",
    "\n",
    "Resposta: JFK → HNL (média 623.09 min)\n",
    "\n",
    "### Pergunta 12\n",
    "\n",
    "**Para cada aeroporto de origem, qual é o aeroporto de destino mais comum?**\n",
    "\n",
    "Resposta: EWR → ORD , JFK → LAX,  LGA → ATL\n",
    "\n",
    "### Pergunta 13\n",
    "\n",
    "**Quais são as 3 rotas que tiveram a maior variação no tempo médio de voo (air_time) ?**\n",
    "\n",
    "Resposta: EWR→HNL 21.24 minutos, LGA→MYR 20.68 minutos, JFK→HNL 20.66 minuttos\n",
    "\n",
    "### Pergunta 14\n",
    "\n",
    "**Qual é a média de atraso na chegada para voos que tiveram atraso na partida superior a 1 hora?**\n",
    "\n",
    "Resposta: 119.05 minutos\n",
    "\n",
    "### Pergunta 15\n",
    "\n",
    "**Qual é a média de voos diários para cada mês do ano?**\n",
    "\n",
    "Resposta:\n",
    "\n",
    "[(1, 871.1), (2, 891.1), (3, 930.1), (4, 944.3), (5, 928.9), (6, 941.4), (7, 949.2), (8, 946.0), (9, 919.1), (10, 931.9), (11, 908.9), (12, 907.6)]\n",
    "\n",
    "| Mês  | Percentual |\n",
    "| ---- | ---------- |\n",
    "| 1    | 871.1      |\n",
    "| 2    | 891.1      |\n",
    "| 3    | 930.1      |\n",
    "| 4    | 944.3      |\n",
    "| 5    | 928.9      |\n",
    "| 6    | 941.4      |\n",
    "| 7    | 949.2      |\n",
    "| 8    | 946.0      |\n",
    "| 9    | 946.0      |\n",
    "| 10   | 931.9      |\n",
    "| 11   | 908.9      |\n",
    "| 12   | 907.6      |\n",
    "\n",
    "### Pergunta 16\n",
    "\n",
    "**Quais são as 3 rotas mais comuns que tiveram atrasos na chegada superiores a 30 minutos?**\n",
    "\n",
    "Resposta:\n",
    "\n",
    "| Rota    | Quantidade |\n",
    "| --------| ---------- |\n",
    "| LGA→ATL | 1563       |\n",
    "| JFK→LAX | 1286       |\n",
    "| LGA→ORD | 1188       |\n",
    "\n",
    "### Pergunta 17\n",
    "\n",
    "**Para cada origem, qual o principal destino?**\n",
    "\n",
    "Resposta: EWR → ORD , JFK → LAX,  LGA → ATL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe Pergunta_Final\n",
    "\n",
    "A classe isola a última tarefa do case: listar os 5 voos com maior atraso na chegada usando o DataFrame que já contém todas as colunas enriquecidas (GMT, ventos, horários reais).\n",
    "\n",
    "---\n",
    "\n",
    "### __Construtor init__(df_enriquecido)\n",
    "\n",
    "* Objetivo – Armazenar o DataFrame resultante do pipeline de enriquecimento.\n",
    "* Parâmetro df_enriquecido – DataFrame Spark contendo, pelo menos, as colunas:\n",
    "  origin, dest, sched_dep_time, dep_delay, wind_origin, arr_real, arr_delay, wind_dest.\n",
    "* Guarda esse dataframe em self.df para uso posterior.\n",
    "\n",
    "---\n",
    "\n",
    "### exibir_top5_atraso_chegada()\n",
    "\n",
    "* Passo 1 – Define colunas_desejadas, lista das colunas que serão mostradas na saída.\n",
    "  Foca nas métricas pedidas: aeroportos, horários, atrasos e velocidades de vento.\n",
    "* Passo 2 – Ordena o DataFrame por arr_delay em ordem decrescente com F.desc_nulls_last(\"arr_delay\"), colocando linhas sem valor de atraso (nulas) no final – assim não se perdem registros válidos.\n",
    "* Passo 3 – Aplica select(*colunas_desejadas) para manter só as colunas relevantes e limit(5) para pegar os cinco piores atrasos.\n",
    "  (o exemplo usou limit(6) por engano; ajuste para 5 se desejar estritamente.)\n",
    "* Passo 4 – Usa collect() para trazer as 5 linhas ao driver e imprime, formatando cada campo num texto amigável.\n",
    "  Mantém quaisquer valores None caso dados de vento ou horários estejam ausentes – evita perder linhas por falha de informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24534,
     "status": "ok",
     "timestamp": 1745001224803,
     "user": {
      "displayName": "Estefano Nascimento",
      "userId": "00926361525390533690"
     },
     "user_tz": 180
    },
    "id": "hAcx2cm0IqxO",
    "outputId": "b2586913-830f-4414-c86a-772b7cc5775f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔶 5 voos com maior atraso na chegada:\n",
      "1. JFK→HNL |  Hor. previsto: 900  | Atraso decolagem: 1301.0 min  | Vento origem: 3.6 m/s  | Chegada real: None  | Atraso chegada: 1272.0 min  | Vento destino: None m/s\n",
      "2. JFK→CMH |  Hor. previsto: 1935  | Atraso decolagem: 1137.0 min  | Vento origem: 7.1 m/s  | Chegada real: 2013-06-16 15:11:00  | Atraso chegada: 1127.0 min  | Vento destino: 19.6 m/s\n",
      "3. EWR→ORD |  Hor. previsto: 1635  | Atraso decolagem: 1126.0 min  | Vento origem: 11.2 m/s  | Chegada real: 2013-01-11 11:37:00  | Atraso chegada: 1109.0 min  | Vento destino: 17.1 m/s\n",
      "4. JFK→SFO |  Hor. previsto: 1845  | Atraso decolagem: 1014.0 min  | Vento origem: 15.5 m/s  | Chegada real: 2013-09-21 13:48:00  | Atraso chegada: 1007.0 min  | Vento destino: 14.2 m/s\n",
      "5. JFK→CVG |  Hor. previsto: 1600  | Atraso decolagem: 1005.0 min  | Vento origem: 11.6 m/s  | Chegada real: 2013-07-23 10:21:00  | Atraso chegada: 989.0 min  | Vento destino: 9.7 m/s\n",
      "6. JFK→TPA |  Hor. previsto: 1900  | Atraso decolagem: 960.0 min  | Vento origem: 9.4 m/s  | Chegada real: 2013-04-11 13:19:00  | Atraso chegada: 931.0 min  | Vento destino: 17.8 m/s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf‑8 -*-\n",
    "\"\"\"\n",
    "Classe Pergunta_Final\n",
    "─────────────────────\n",
    "Exibe, a partir do DataFrame **já enriquecido**, os 5 voos com MAIOR atraso na\n",
    "chegada, mostrando:\n",
    "\n",
    "• origin          – aeroporto de saída\n",
    "• dest            – aeroporto de destino\n",
    "• sched_dep_time  – horário programado de decolagem\n",
    "• dep_delay       – atraso (ou adiantamento) na decolagem ‑‑ em minutos\n",
    "• wind_origin     – velocidade do vento na origem (m/s) no instante da partida\n",
    "• arr_real        – horário real de chegada (timestamp string)\n",
    "• arr_delay       – atraso (ou adiantamento) na chegada ‑‑ em minutos\n",
    "• wind_dest       – velocidade do vento no destino (m/s) no instante do pouso\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "class Pergunta_Final:\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    def __init__(self, df_enriquecido):\n",
    "        self.df = df_enriquecido\n",
    "\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    def exibir_top5_atraso_chegada(self):\n",
    "        \"\"\"\n",
    "        Seleciona as 5 maiores arr_delay (desc), exibe colunas de interesse.\n",
    "        Se houver valores nulos, eles são mantidos na saída para não perder linhas.\n",
    "        \"\"\"\n",
    "        colunas_desejadas = [\n",
    "            \"origin\",\n",
    "            \"dest\",\n",
    "            \"sched_dep_time\",\n",
    "            \"dep_delay\",\n",
    "            \"wind_origin\",\n",
    "            \"arr_real\",\n",
    "            \"arr_delay\",\n",
    "            \"wind_dest\",\n",
    "        ]\n",
    "\n",
    "        top5 = (\n",
    "            self.df.orderBy(F.desc_nulls_last(\"arr_delay\"))\n",
    "            .select(*colunas_desejadas)\n",
    "            .limit(6)\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "        print(\"\\n🔶 5 voos com maior atraso na chegada:\")\n",
    "        for idx, linha in enumerate(top5, 1):\n",
    "            print(\n",
    "                f\"{idx}. {linha['origin']}→{linha['dest']} |  \"\n",
    "                f\"Hor. previsto: {linha['sched_dep_time']}  | \"\n",
    "                f\"Atraso decolagem: {linha['dep_delay']} min  | \"\n",
    "                f\"Vento origem: {linha['wind_origin']} m/s  | \"\n",
    "                f\"Chegada real: {linha['arr_real']}  | \"\n",
    "                f\"Atraso chegada: {linha['arr_delay']} min  | \"\n",
    "                f\"Vento destino: {linha['wind_dest']} m/s\"\n",
    "            )\n",
    "pergunta_final = Pergunta_Final(df_final)\n",
    "pergunta_final.exibir_top5_atraso_chegada()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pergunta Final\n",
    "\n",
    "🔶 6 voos com maior atraso na chegada (originalmente eram 5 mas o primeiro aeroporto de destino não foi encontrado pela api ):\n",
    "\n",
    "1. JFK→HNL |  Hor. previsto: 900  | Atraso decolagem: 1301.0 min  | Vento origem: 3.6 m/s  | Chegada real: None  | Atraso chegada: 1272.0 min  | Vento destino: None m/s **(O areroporto HNL não foi encontrado pela API)**\n",
    "2. JFK→CMH |  Hor. previsto: 1935  | Atraso decolagem: 1137.0 min  | Vento origem: 7.1 m/s  | Chegada real: 2013-06-16 15:11:00  | Atraso chegada: 1127.0 min  | Vento destino: 19.6 m/s\n",
    "3. EWR→ORD |  Hor. previsto: 1635  | Atraso decolagem: 1126.0 min  | Vento origem: 11.2 m/s  | Chegada real: 2013-01-11 11:37:00  | Atraso chegada: 1109.0 min  | Vento destino: 17.1 m/s\n",
    "4. JFK→SFO |  Hor. previsto: 1845  | Atraso decolagem: 1014.0 min  | Vento origem: 15.5 m/s  | Chegada real: 2013-09-21 13:48:00  | Atraso chegada: 1007.0 min  | Vento destino: 14.2 m/s\n",
    "5. JFK→CVG |  Hor. previsto: 1600  | Atraso decolagem: 1005.0 min  | Vento origem: 11.6 m/s  | Chegada real: 2013-07-23 10:21:00  | Atraso chegada: 989.0 min  | Vento destino: 9.7 m/s\n",
    "6. JFK→TPA |  Hor. previsto: 1900  | Atraso decolagem: 960.0 min  | Vento origem: 9.4 m/s  | Chegada real: 2013-04-11 13:19:00  | Atraso chegada: 931.0 min  | Vento destino: 17.8 m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe Treino\n",
    "\n",
    "A classe organiza todo o pipeline de modelagem que relaciona a velocidade do vento na origem (wind_origin) com o atraso na decolagem (dep_delay).\n",
    " Recebe o DataFrame Spark enriquecido, executa as etapas de pré‑processamento, treino, avaliação e persistência do modelo em um único fluxo.\n",
    "\n",
    "---\n",
    "\n",
    "### Construtor __init__(df_spark, caminho_saida=\"modelo_wind_delay.pkl\")\n",
    "\n",
    "* Guarda o DataFrame Spark original em self.df_spark.\n",
    "* Define o caminho do arquivo onde o modelo será salvo (self.caminho_pkl).\n",
    "* Cria self.modelo = None, que será preenchido depois do treino.\n",
    "\n",
    "---\n",
    "\n",
    "### preparar_dados()\n",
    "\n",
    "* Seleciona apenas as colunas necessárias – wind_origin e dep_delay.\n",
    "* Remove nulos com filter() para evitar erros de treino.\n",
    "* Converte o resultado para pandas (toPandas()), pois o conjunto é pequeno (2 colunas) e simplifica a integração com scikit‑learn.\n",
    "* Imprime quantas linhas restaram após a limpeza.\n",
    "\n",
    "---\n",
    "\n",
    "### dividir_treino_teste()\n",
    "\n",
    "* Extrai X (feature) como matriz 2‑D e y (target) como vetor.\n",
    "* Usa train_test_split com proporção 80 % / 20 % e random_state=42 para reprodutibilidade.\n",
    "* Armazena em self.X_train, self.X_test, self.y_train, self.y_test.\n",
    "\n",
    "---\n",
    "\n",
    "### treinar_modelo()\n",
    "\n",
    "* Instancia LinearRegression() – modelo mais simples possível de regressão.\n",
    "* Ajusta (fit) com os dados de treino.\n",
    "* Salva o objeto treinado em self.modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### avaliar_modelo()\n",
    "\n",
    "* Aplica predict() no conjunto de teste.\n",
    "* Calcula e imprime três métricas básicas:\n",
    "\n",
    "  * MAE (erro absoluto médio)\n",
    "  * RMSE (raiz do erro quadrático médio)\n",
    "  * R² (coeficiente de determinação)\n",
    "* Não há exigência de boa performance – a etapa serve apenas para demonstrar a avaliação.\n",
    "\n",
    "---\n",
    "\n",
    "### salvar_modelo()\n",
    "\n",
    "* Usa joblib.dump() para serializar self.modelo no caminho definido.\n",
    "* O arquivo .pkl servirá para ser carregado pela API posteriormente.\n",
    "\n",
    "---\n",
    "\n",
    "### executar_tudo()\n",
    "\n",
    "* Método orquestrador que chama, na ordem correta, todos os passos:\n",
    "\n",
    "  1. preparar_dados\n",
    "  2. dividir_treino_teste\n",
    "  3. treinar_modelo\n",
    "  4. avaliar_modelo\n",
    "  5. salvar_modelo\n",
    "* Retorna o objeto modelo treinado, facilitando uso imediato em memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1837,
     "status": "ok",
     "timestamp": 1745002384755,
     "user": {
      "displayName": "Estefano Nascimento",
      "userId": "00926361525390533690"
     },
     "user_tz": 180
    },
    "id": "CUUptnVPK4lN"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf‑8 -*-\n",
    "\"\"\"\n",
    "Classe Treino\n",
    "─────────────\n",
    "Treina um modelo simples que estima o atraso na decolagem (dep_delay)\n",
    "a partir da velocidade do vento na origem (wind_origin).\n",
    "\n",
    "• Recebe um DataFrame Spark já enriquecido.\n",
    "• Executa: limpeza → split → treino → avaliação → salva .pkl.\n",
    "• Retorna o objeto modelo treinado.\n",
    "\n",
    "Dependências:\n",
    "-------------\n",
    "pandas\n",
    "scikit‑learn\n",
    "joblib\n",
    "\"\"\"\n",
    "\n",
    "from math import sqrt\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "class Treino:\n",
    "    # ─────────────────────────────────────────────────────────────\n",
    "    def __init__(self, df_spark, caminho_saida=\"modelo_wind_delay.pkl\"):\n",
    "        \"\"\"\n",
    "        df_spark      : DataFrame PySpark com colunas 'wind_origin' e 'dep_delay'\n",
    "        caminho_saida : onde salvar o arquivo .pkl\n",
    "        \"\"\"\n",
    "        self.df_spark = df_spark\n",
    "        self.caminho_pkl = caminho_saida\n",
    "        self.modelo = None                 # será preenchido após treinamento\n",
    "\n",
    "    # ───────────────────────── 1. Preparar dados\n",
    "    def preparar_dados(self):\n",
    "        \"\"\"Seleciona colunas, remove nulos e converte para pandas.\"\"\"\n",
    "        print(\"🔹 Preparando dados …\")\n",
    "        df_limpo = (\n",
    "            self.df_spark.select(\"wind_origin\", \"dep_delay\")\n",
    "            .filter(F.col(\"wind_origin\").isNotNull() & F.col(\"dep_delay\").isNotNull())\n",
    "        )\n",
    "        self.df_pandas = df_limpo.toPandas()   # 2 colunas → cabe bem em RAM\n",
    "        print(f\"   Linhas após limpeza: {len(self.df_pandas)}\")\n",
    "\n",
    "    # ───────────────────────── 2. Split em treino / teste\n",
    "    def dividir_treino_teste(self):\n",
    "        \"\"\"Separa X (feature) e y (target) + faz train_test_split.\"\"\"\n",
    "        print(\"🔹 Dividindo treino / teste …\")\n",
    "        X = self.df_pandas[[\"wind_origin\"]].values\n",
    "        y = self.df_pandas[\"dep_delay\"].values\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.20, random_state=42\n",
    "        )\n",
    "        print(f\"   Treino: {len(self.X_train)}  |  Teste: {len(self.X_test)}\")\n",
    "\n",
    "    # ───────────────────────── 3. Treinar modelo\n",
    "    def treinar_modelo(self):\n",
    "        \"\"\"Ajusta Regressão Linear simples.\"\"\"\n",
    "        print(\"🔹 Treinando modelo …\")\n",
    "        self.modelo = LinearRegression()\n",
    "        self.modelo.fit(self.X_train, self.y_train)\n",
    "        print(\"   ✅ Treino concluído\")\n",
    "\n",
    "    # ───────────────────────── 4. Avaliar\n",
    "    def avaliar_modelo(self):\n",
    "        \"\"\"Calcula MAE, RMSE e R² no conjunto de teste.\"\"\"\n",
    "        print(\"🔹 Avaliando modelo …\")\n",
    "        y_pred = self.modelo.predict(self.X_test)\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "        rmse = sqrt(mean_squared_error(self.y_test, y_pred))\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        print(f\"   MAE : {mae:.2f}\")\n",
    "        print(f\"   RMSE: {rmse:.2f}\")\n",
    "        print(f\"   R²  : {r2:.3f}\")\n",
    "\n",
    "    # ───────────────────────── 5. Salvar em .pkl\n",
    "    def salvar_modelo(self):\n",
    "        \"\"\"Grava o modelo em arquivo .pkl (joblib).\"\"\"\n",
    "        joblib.dump(self.modelo, self.caminho_pkl)\n",
    "        print(f\"🔹 Modelo salvo em {self.caminho_pkl}\")\n",
    "\n",
    "    # ───────────────────────── 6. Pipeline completo\n",
    "    def executar_tudo(self):\n",
    "        \"\"\"Roda todas as etapas na ordem correta e devolve o modelo treinado.\"\"\"\n",
    "        self.preparar_dados()\n",
    "        self.dividir_treino_teste()\n",
    "        self.treinar_modelo()\n",
    "        self.avaliar_modelo()\n",
    "        self.salvar_modelo()\n",
    "        return self.modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26746,
     "status": "ok",
     "timestamp": 1745002421256,
     "user": {
      "displayName": "Estefano Nascimento",
      "userId": "00926361525390533690"
     },
     "user_tz": 180
    },
    "id": "w_OALDkKPzxj",
    "outputId": "c7d0e5b5-fbff-46ed-acb4-5ed0a38a9b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparando dados …\n",
      "   Linhas após limpeza: 328521\n",
      "🔹 Dividindo treino / teste …\n",
      "   Treino: 262816  |  Teste: 65705\n",
      "🔹 Treinando modelo …\n",
      "   ✅ Treino concluído\n",
      "🔹 Avaliando modelo …\n",
      "   MAE : 23.12\n",
      "   RMSE: 40.51\n",
      "   R²  : 0.003\n",
      "🔹 Modelo salvo em modelo_wind_delay.pkl\n",
      "Atraso estimado p/ vento 4.8 m/s: 9.7 min\n"
     ]
    }
   ],
   "source": [
    "# df_final é o DataFrame Spark já enriquecido (wind_origin + dep_delay não nulos)\n",
    "treino = Treino(df_final)               # construtor recebe o DataFrame\n",
    "modelo_treinado = treino.executar_tudo()   # executa pipeline completo\n",
    "\n",
    "\n",
    "import joblib\n",
    "modelo = joblib.load(\"modelo_wind_delay.pkl\")\n",
    "atraso_prev = modelo.predict([[4.8]])[0]\n",
    "print(f\"Atraso estimado p/ vento 4.8 m/s: {atraso_prev:.1f} min\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOOxOY+Hxu0zrmzggI16IS1",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
